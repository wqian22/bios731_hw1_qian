---
title: "Homework 1"
output:
  html_document:
    df_print: paged
  pdf_document:
    keep_tex: true
header-includes:
- \usepackage{float}
- \usepackage{multirow}
urlcolor: blue
---

```{r, include=FALSE}
library(CCMHr)
library(gt)
library(here)
library(tidyverse)
knitr::opts_chunk$set(tidy = FALSE, echo = FALSE, warning = FALSE)
```


### Problem 1.1 ADEMP Structure 

Answer the following questions: 

* How many simulation scenarios will you be running?

18 scenarios.

* What are the estimand(s)

The average treatment effect ($\beta_{treatment}$)

* What method(s) are being evaluated/compared?

The study evaluates the multiple linear regression model and compares three methods for constructing confidence intervals: 1) Wald confidence intervals; 2) nonparametric bootstrap percentile intervals; 3) nonparametric bootstrap-t intervals.

* What are the performance measure(s)?
  * Bias of $\hat{\beta}$
  * Coverage of $\hat{\beta}$
  * Distribution of $se(\hat{\beta})$
  * Computation time across methods


### Problem 1.2 nSim 

Based on desired coverage of 95\% with Monte Carlo error of no more than 1\%, how many simulations ($n_{sim}$) should we perform for each simulation scenario?  Implement this number of simulations throughout your simulation study.

```{r}
nsim <- 0.95 * (1 - 0.95) / (0.01)^2
```

We should perform `r nsim` simulations for each scenario.


### Problem 1.3 Implementation 

### Problem 1.4 Results summary

#### Bias of $\hat{\beta}$

```{r, results = 'asis'}
# load simulation results
rda_files <- list.files(here("results"), pattern = "\\.RDA$", full.names = TRUE)
all_results <- list()
for (i in 1:length(rda_files)) {
  all_results[[i]] <- loadRDa(rda_files[[i]])
}
all_df <- do.call(rbind, all_results)

# summarize the data
table_bias <- all_df %>%
  group_by(family, n, beta_true) %>%
  summarise(
    bias = mean(bias, na.rm = TRUE),
    .groups = "drop"
  )

table_bias_wide <- table_bias %>%
    pivot_wider(names_from = c(n, beta_true), values_from = bias, names_sep = "_beta_")

# create a gt table
table_bias_wide %>%
    gt(groupname_col = "family") %>%
    tab_spanner(label = "n = 10", columns = starts_with("10_")) %>%
    tab_spanner(label = "n = 50", columns = starts_with("50_")) %>%
    tab_spanner(label = "n = 500", columns = starts_with("500_")) %>%
    cols_label(ends_with("beta_0") ~ md("$\\beta$ = 0"),
               ends_with("beta_0.5") ~ md("$\\beta$ = 0.5"),
               ends_with("beta_2") ~ md("$\\beta$ = 2")) %>%
    tab_header(title = md("Average Bias of $\\hat{\\beta}$ Across 475 Simulations")) %>%
    cols_align(align = "center", columns = everything()) %>%
    fmt_number(columns = where(is.numeric), decimals = 3) %>%
    opt_table_outline() %>%
    opt_row_striping()

```

#### Coverage of $\hat{\beta}$

```{r, results = 'asis'}
# summarize the data
table_coverage <- all_df %>%
  group_by(family, n, beta_true) %>%
  summarize(
    coverage_wald = mean(coverage_wald, na.rm = TRUE),
    coverage_percentile = mean(coverage_percentile, na.rm = TRUE),
    coverage_t = mean(coverage_t, na.rm = TRUE),
    .groups = "drop"
  )

# create a gt table
gt(table_coverage) %>%
  tab_header(
    title = "Average Coverage of 95% Wald, Percentile & Bootstrap-t CIs",
  ) %>%
  fmt_number(
    columns = starts_with("coverage"),
    decimals = 3
  )
```

#### Distribution of $se(\hat{\beta})$

```{r, fig.align="center"}
# reshape data to long format for easier plotting
long_df <- all_df %>%
  select(n, beta_true, family, se_wald, se_boot) %>%
  pivot_longer(cols = c(se_wald, se_boot), names_to = "se_method", values_to = "se_value") %>%
  mutate(se_method = recode(se_method, 
                            "se_boot" = "Bootstrap SE", 
                            "se_wald" = "Wald SE"))

# create a faceted boxplot
ggplot(long_df, aes(x = se_method, y = se_value, fill = se_method)) +
  geom_boxplot(alpha = 0.6) +
  facet_grid(family ~ n + beta_true, scales = "free", 
             labeller = labeller(
               n = label_both,
               beta_true = function(x) paste0("beta: ", x)
             )) + 
  coord_cartesian(ylim = c(0, 5)) +  # Fixes y-axis range
  theme_minimal() +
  labs(
    title = "Comparison of Wald and Boostrap SE Estimates",
    x = NULL, 
    y = "Standard Error",
    fill = "Method"
  ) +
  theme(
    axis.text.x = element_blank(),
    axis.ticks.x = element_blank(), 
    legend.position = "bottom"
  )
```

#### Computation time across methods
```{r, results = 'asis'}
# summarize the data
table_time <- all_df %>%
  group_by(family, n, beta_true) %>%
  summarize(
    time_wald = mean(time_wald, na.rm = TRUE),
    time_percentile = mean(time_percentile, na.rm = TRUE),
    time_t = mean(time_t, na.rm = TRUE),
    .groups = "drop"
  )

# create a gt table
gt(table_time) %>%
  tab_header(
    title = "Average Computation Time for Wald, Percentile & Bootstrap-t CIs",
  ) %>%
  fmt_number(
    columns = starts_with("time"),
    decimals = 3
  )
```


### Problem 1.5 Discussion

Summary of main findings:

The bias of $\hat{\beta}$ decreases as the sample size (n) increases. In small samples (n = 10 or 50), misspecifying the error distribution leads to biased estimates when the true error distribution is lognormal, but this bias diminishes in larger samples (n = 500). The Wald confidence interval maintains coverage near its nominal level (95\%) when the error distribution is normal and slightly exceeds it when the true distribution is lognormal, likely due to conservative standard error (SE) estimates under misspecification. The bootstrap percentile interval performs poorly in small samples (n = 10) but improves with increasing n. In contrast, the bootstrap-t interval performs well in small samples but does not improve with larger n. SE estimates from the Wald and bootstrap methods are similar, with bootstrap estimates slightly higher. Under model misspecification, SE estimates exhibit greater variance and right skewness. The variance of SE estimates decreases as n increases. Regarding computation time, the Wald method is the fastest, followed by the percentile method, while the bootstrap-t method is significantly more computationally intensive. No clear trend is observed in bias, coverage, SE, or computation time across different true $\beta$ values.

- Regarding computation time, the Wald method is the fastest, followed by the percentile method, while the bootstrap-t method is significantly more computationally intensive.
- The bootstrap-t method for constructing confidence intervals provides the best coverage when $\epsilon_i \sim N(0, 2)$.
- The Wald method for constructing confidence intervals provides the best coverage when $\epsilon_i \sim logNormal(0, \log (2))$.

GitHub repository: https://github.com/wqian22/bios731_hw1_qian.git

